{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle of Maximum Likelihood\n",
    "\n",
    "\n",
    "## Description:\n",
    "\n",
    "Python script for illustrating the principle of maximum likelihood and a likelihood fit.\n",
    "\n",
    "__This is both an exercise, but also an attempt to illustrate four things:__\n",
    "  1. How to make a (binned and unbinned) Likelihood function/fit.\n",
    "  2. The difference and a comparison between a Chi-square and a (binned) Likelihood.\n",
    "  3. The difference and a comparison between a binned and unbinned Likelihood.\n",
    "  4. What goes on behind the scenes in Minuit, when it is asked to fit something.\n",
    "\n",
    "In this respect, the exercise is more of an illustration rather than something to be used directly, which is why it is followed later by another exercise, where you can test if you have understood the differences, and how and when to apply which fit method.\n",
    "\n",
    "The example uses 50 exponentially distributed random times, with the goal of finding the best estimate of the lifetime (data is generated with lifetime, tau = 1). Three estimates are considered:\n",
    "  1. Chi-square fit (chi2)\n",
    "  2. Binned Likelihood fit (bllh)\n",
    "  3. Unbinned Likelihood fit (ullh)\n",
    "\n",
    "While the mean can be simply calculated, the three other methods are based on a scan of values for tau in the range [0.5, 2.0]. For each value of tau, the chi2, bllh, and llh are calculated. In the two likelihood cases, it is actually -2*log(likelihood) which is calculated, which you should (by now) understand why.\n",
    " \n",
    "Note that the unbinned likelihood is in principle the \"optimal\" fit, but also the most difficult for several reasons (convergence, numerical problems, implementation, speed, etc.). However, all three methods/constructions essentially yield the same results, when there is enough statistics (i.e. errors are Gaussian), though the $\\chi^2$ also gives a fit quality.\n",
    " \n",
    "The problem is explicitly chosen to have only one fit parameter, such that simple 1D graphs can show what goes on. In this case, the analytical solution is actually prefered (see Barlow). Real world problems will almost surely be more complex. Also, it is meant more for illustration, as in reality, one tends to simply do the minimization using an algorithm (Minuit) to do the hard work.\n",
    "\n",
    "### Authors: \n",
    "- Troels C. Petersen (Niels Bohr Institute, petersen@nbi.dk)\n",
    "- Ã‰tienne Bourbeau (etienne.bourbeau@icecube.wisc.edu)\n",
    "\n",
    "### Date:    \n",
    "- 23-11-2018 (latest update)\n",
    "\n",
    "### Reference:\n",
    "- Barlow, chapter 5 (5.1-5.3)\n",
    "- Cowan, chapter 6\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "import seaborn as sns                                  # Make the plots nicer to look at\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "from probfit import BinnedLH, Chi2Regression, Extended # Helper tool for fitting\n",
    "import sys                                             # Module to see files and folders in directories\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../External_Functions')\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax # useful functions to print fit results on figure\n",
    "\n",
    "plt.rcParams['font.size'] = 18 # set some basic plotting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plots = False     # Determining if plots are saved or not\n",
    "verbose = True         # Should the program print or not?\n",
    "veryverbose = True     # Should the program print a lot or not?\n",
    "\n",
    "ScanChi2 = True        # In addition to fit for minimum, do a scan...\n",
    "\n",
    "# Parameters of the problem:\n",
    "Ntimes = 10000           # Number of time measurements.\n",
    "tau_truth = 1.0;       # We choose (like Gods!) the lifetime.\n",
    "\n",
    "# Binning:\n",
    "Nbins = 50             # Number of bins in histogram\n",
    "tmax = 10.0            # Maximum time in histogram\n",
    "dt = tmax / Nbins      # Time step\n",
    "\n",
    "# General settings:\n",
    "r = np.random          # Random numbers\n",
    "r.seed(42)             # We set the numbers to be random, but the same for each run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Generate data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce (list of) exponentially distributed times and put them in a histogram:\n",
    "t = r.exponential(tau_truth, Ntimes) # Exponential with lifetime tau.\n",
    "yExp, xExp_edges = np.histogram(t, bins=Nbins, range=(0, tmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the data plotted like we wouls like to? Let's check..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# In case you want to check that the numbers really come out as you want to (very healthy to do at first):\n",
    "if (veryverbose) :\n",
    "    for index, time in enumerate(t) :\n",
    "        print(f\"  {index:2d}:   t = {time:5.3f}\")\n",
    "        if index > 10: \n",
    "            break # let's restrain ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like values are coming int, but are they actually giving an exponential? Remember the importance of __plotting your data before hand__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_center = xExp_edges[:-1] + (xExp_edges[1]-xExp_edges[0])/2. # get the value of the histogram bin centers\n",
    "plt.plot(X_center,yExp,'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are producing the data we that we want. So let's move on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse data:\n",
    "The following is \"a manual fit\", i.e. scanning over possible values of the fitting parameter(s) - here luckely only one, tau - and seeing what value of chi2, bllh, and llh it yields. When plotting these, one should find a parabola, the minimum value of which is the optimal fitting parameter of tau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define the number of tau values and their range to test in Chi2 and LLH:\n",
    "# (As we know the \"truth\", namely tau = 1, the range [0.5, 1.5] seems fitting\n",
    "# for the mean. The number of bins can be increased at will...)\n",
    "Ntau_steps = 50\n",
    "min_tau = 0.5\n",
    "max_tau = 1.5\n",
    "delta_tau = (max_tau-min_tau) / Ntau_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over hypothesis for the value of tau and calculate Chi2 and (B)LLH:\n",
    "chi2_minval = 999999.9   # Minimal Chi2 value found\n",
    "chi2_minpos = 0.0        # Position (i.e. time) of minimal Chi2 value\n",
    "bllh_minval = 999999.9\n",
    "bllh_minpos = 0.0\n",
    "ullh_minval = 999999.9\n",
    "ullh_minpos = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau  = np.zeros(Ntau_steps+1)\n",
    "chi2 = np.zeros(Ntau_steps+1)\n",
    "bllh = np.zeros(Ntau_steps+1)\n",
    "ullh = np.zeros(Ntau_steps+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now loop of POSSIBLE tau estimates:\n",
    "for itau in range(Ntau_steps+1):\n",
    "    tau_hypo = min_tau + itau*delta_tau         # Scan in values of tau\n",
    "    tau[itau] = tau_hypo\n",
    "\n",
    "    # Calculate Chi2 and binned likelihood (from loop over bins in histogram):\n",
    "    chi2[itau] = 0.0\n",
    "    bllh[itau] = 0.0\n",
    "    for ibin in range (Nbins) :\n",
    "        # Note: The number of EXPECTED events is the intergral over the bin!\n",
    "        xlow_bin = xExp_edges[ibin]\n",
    "        xhigh_bin = xExp_edges[ibin+1]\n",
    "        # Given the start and end of the bin, we calculate the INTEGRAL over the bin,\n",
    "        # to get the expected number of events in that bin:\n",
    "        nexp = Ntimes * (np.exp(-xlow_bin/tau_hypo) - np.exp(-xhigh_bin/tau_hypo))\n",
    "        # The observed number of events... that is just the data!\n",
    "        nobs = yExp[ibin]\n",
    "\n",
    "        if (nobs > 0):             # For ChiSquare but not LLH, we need to require Nobs > 0, as we divide by this:\n",
    "            chi2[itau] += (nobs-nexp)**2 / nobs                    # Chi2 summation/function\n",
    "        bllh[itau] += -2.0*np.log(stats.poisson.pmf(int(nobs), nexp))     # Binned LLH function\n",
    "\n",
    "        if (veryverbose and itau == 0) :\n",
    "            print(f\"  Nexp: {nexp:10.7f}   Nobs: {nobs:3.0f}     Chi2: {chi2[itau]:5.1f}    BLLH: {bllh[itau]:5.1f}\")\n",
    "\n",
    "    # Calculate Unbinned likelihood (from loop over events):\n",
    "    ullh[itau] = 0.0\n",
    "    for time in t : # ie for every data point generated...\n",
    "        ullh[itau] += -2.0*np.log(1.0/tau_hypo*np.exp(-time/tau_hypo))   # Unbinned LLH function\n",
    "    \n",
    "    if (verbose) :\n",
    "        print(f\" {itau:3d}:  tau = {tau_hypo:4.2f}   chi2 = {chi2[itau]:6.2f}   log(bllh) = {bllh[itau]:6.2f}   log(ullh) = {ullh[itau]:6.2f}\")\n",
    "\n",
    "    # Search for minimum values of chi2, bllh, and ullh:\n",
    "    if (chi2[itau] < chi2_minval) :\n",
    "        chi2_minval = chi2[itau]\n",
    "        chi2_minpos = tau_hypo\n",
    "    if (bllh[itau] < bllh_minval) :\n",
    "        bllh_minval = bllh[itau]\n",
    "        bllh_minpos = tau_hypo\n",
    "    if (ullh[itau] < ullh_minval) :\n",
    "        ullh_minval = ullh[itau]\n",
    "        ullh_minpos = tau_hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  Decay time of minimum found:   chi2 = {chi2_minpos:7.4f}s    bllh = {bllh_minpos:7.4f}s    ullh = {ullh_minpos:7.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and fit results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define range around minimum to be fitted:\n",
    "min_fit = 0.15\n",
    "max_fit = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(12, 12))\n",
    "\n",
    "ax_chi2 = axes[0,0]\n",
    "ax_bllh = axes[1,0]\n",
    "ax_ullh = axes[0,1]\n",
    "# A fourth plot is available for plotting whatever you want :)\n",
    "\n",
    "# ChiSquare:\n",
    "# ----------\n",
    "ax_chi2.plot(tau, chi2, 'k.', label='chi2')\n",
    "ax_chi2.set_xlim(chi2_minpos-2*min_fit, chi2_minpos+2*max_fit)\n",
    "ax_chi2.set_title(\"ChiSquare\")\n",
    "ax_chi2.set_xlabel(r\"Value of $\\tau$\")\n",
    "ax_chi2.set_ylabel(\"Value of ChiSquare\")\n",
    "\n",
    "# Binned Likelihood:\n",
    "# ----------\n",
    "ax_bllh.plot(tau, bllh,'bo')\n",
    "ax_bllh.set_xlim(bllh_minpos-2*min_fit, bllh_minpos+2*max_fit)\n",
    "ax_bllh.set_title(\"Binned Likelihood\")\n",
    "ax_bllh.set_xlabel(r\"Value of $\\tau$\")\n",
    "ax_bllh.set_ylabel(r\"Value of $\\ln{LLH}$\")\n",
    "\n",
    "\n",
    "# Unbinned Likelihood:\n",
    "# ----------\n",
    "ax_ullh.plot(tau, ullh, 'g.')\n",
    "ax_ullh.set_xlim(ullh_minpos-2*min_fit, ullh_minpos+2*max_fit)\n",
    "ax_ullh.set_title(\"Unbinned Likelihood\")\n",
    "ax_ullh.set_xlabel(r\"Value of $\\tau$\")\n",
    "ax_ullh.set_ylabel(r\"Value of $\\ln{LLH}$\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parabola function\n",
    "Note that the parabola is defined differently than normally. The Parameters are:\n",
    "   * `minval`:    Minimum value (i.e. constant)\n",
    "   * `minpos`:    Minimum position (i.e. x of minimum)\n",
    "   * `quadratic`: Quadratic term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_para(x, minval, minpos, quadratic) :\n",
    "    return minval + quadratic*(x-minpos)**2\n",
    "func_para_vec = np.vectorize(func_para)           # Note: This line makes it possible to send vectors through the function! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Double parabola with different slopes on each side of the minimum:\n",
    "Parameters are as follows:\n",
    "   * `minval`:   Minimum value (i.e. constant)\n",
    "   * `minpos`:   Minimum position (i.e. x of minimum)\n",
    "   * `quadlow`:  Quadratic term on lower side\n",
    "   * `quadhigh`: Quadratic term on higher side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_asympara(x, minval, minpos, quadlow, quadhigh) :\n",
    "    if (x < minpos) :\n",
    "        return minval + quadlow*(x-minpos)**2\n",
    "    else :\n",
    "        return minval + quadhigh*(x-minpos)**2\n",
    "func_asympara_vec = np.vectorize(func_asympara)   # Note: This line makes it possible to send vectors through the function! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform both fits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit chi2 values with our parabola:\n",
    "indexes = (tau>chi2_minpos-min_fit) & (tau<chi2_minpos+max_fit)\n",
    "\n",
    "# Fit with parabola:\n",
    "chi2_object_chi2 = Chi2Regression(func_para, tau[indexes], chi2[indexes])\n",
    "minuit_chi2 = Minuit(chi2_object_chi2, pedantic=False, minval=chi2_minval, minpos=chi2_minpos, quadratic=20.0, print_level=0)\n",
    "minuit_chi2.migrad()\n",
    "\n",
    "# Fit with double parabola:\n",
    "chi2_object_chi2_doublep = Chi2Regression(func_asympara, tau[indexes], chi2[indexes])\n",
    "minuit_chi2_doublep = Minuit(chi2_object_chi2_doublep, pedantic=False, minval=chi2_minval, minpos=chi2_minpos, quadlow=20.0, quadhigh=20.0, print_level=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minuit_chi2_doublep.migrad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "minval, minpos, quadratic = minuit_chi2.args\n",
    "print(minval)\n",
    "minval_2p, minpos_2p, quadlow_2p, quadhigh_2p = minuit_chi2_doublep.args\n",
    "print(minval_2p)\n",
    "x_fit = np.linspace(chi2_minpos-min_fit, chi2_minpos+max_fit, 1000)\n",
    "\n",
    "y_fit_simple = func_para_vec(x_fit, minval, minpos, quadratic)\n",
    "\n",
    "ax_chi2.plot(x_fit, y_fit_simple, 'b-')\n",
    "\n",
    "d = {'minval':    minval,\n",
    "     'minpos':    minpos,\n",
    "     'quadratic': quadratic}\n",
    "\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.02, 0.95, text, ax_chi2, fontsize=14)\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw lines corresponding to minimum Chi2 and minimum Chi2+1 (same for a normal (=symmetric) parabola), and draw errors:\n",
    "err = 1.0 / np.sqrt(quadratic)\n",
    "\n",
    "# For the asymmetric case, there are naturally two errors to calculate.\n",
    "#err_lower = 1.0 / np.sqrt(quadlow)\n",
    "#err_upper = 1.0 / np.sqrt(quadhigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range in the y-axis to draw in:\n",
    "ax_chi2.set_ylim(minval-2.0, minval+4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that to plot lines, we can directly use plot( [x1,x2,x3,...], [y1,y2,y3...] )\n",
    "ax_chi2.plot([minpos - err, minpos + err], [minval, minval], 'k-', lw=1)\n",
    "#ax_chi2.plot([minpos - err_lower, minpos + err_upper], [minval, minval], 'k-', lw=1)\n",
    "#ax_chi2.plot([minpos - err_lower, minpos + err_upper], [minval+1.0, minval+1.0], 'k-', lw=1)\n",
    "ax_chi2.plot([minpos, minpos], [minval+1.0, minval-2.0], 'k-', lw=1)\n",
    "ax_chi2.plot([minpos-err, minpos-err], [minval+1.0, minval-2.0], 'k-', lw=1)\n",
    "#ax_chi2.plot([minpos-err_lower, minpos-err_lower], [minval+1.0, minval-2.0], 'k-', lw=1)\n",
    "#ax_chi2.plot([minpos+err_upper, minpos+err_upper], [minval+1.0, minval-2.0], 'k-', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  Chi2 fit gives:    tau = {minpos:6.4f} +- {err:6.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if save_plots: \n",
    "    fig_chi2.savefig(\"FitMinimum_chi2.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through tau values to find minimum and +-1 sigma:\n",
    "# This assumes knowing the minimum value, and Chi2s above Chi2_min+1\n",
    "if (ScanChi2) :\n",
    "    if (((chi2[0] - chi2_minval) > 1.0) and ((chi2[Ntau_steps] - chi2_minval) > 1.0)) :\n",
    "        found_lower = False\n",
    "        found_upper = False\n",
    "        for itau in range (Ntau_steps+1) :\n",
    "            if ((not found_lower) and ((chi2[itau] - chi2_minval) < 1.0)) :\n",
    "                tau_lower = tau[itau]\n",
    "                found_lower = True\n",
    "                \n",
    "            if ((found_lower) and (not found_upper) and ((chi2[itau] - chi2_minval) > 1.0)) :\n",
    "                tau_upper = tau[itau]\n",
    "                found_upper = True\n",
    "      \n",
    "    \n",
    "        print(\"  Chi2 scan gives:   tau = {0:6.4f} + {1:6.4f} - {2:6.4f}\".format(chi2_minpos, chi2_minpos-tau_lower, tau_upper-chi2_minpos))\n",
    "    else :\n",
    "        print(\"Error: Chi2 values do not fulfill requirements for finding minimum and errors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned Likelihood:\n",
    "# ------------------\n",
    "# Prepare figure\n",
    "fig_bllh, ax_bllh = plt.subplots(figsize=(8, 6))\n",
    "ax_bllh.set_title(\"Binned Likelihood\")\n",
    "ax_bllh.set_xlabel(r\"Value of $\\tau$\")\n",
    "ax_bllh.set_ylabel(\"Value of Binned Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot binned log likelihood values\n",
    "ax_bllh.plot(tau, bllh, 'k.', )\n",
    "ax_bllh.set_xlim(chi2_minpos-2*min_fit, chi2_minpos+2*max_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit binned log likelihood values with our function\n",
    "indexes = (tau>bllh_minpos-min_fit) & (tau<bllh_minpos+max_fit)\n",
    "chi2_object_bllh = Chi2Regression(func_asympara, tau[indexes], bllh[indexes])\n",
    "minuit_bllh = Minuit(chi2_object_bllh, pedantic=False, minval=bllh_minval, minpos=bllh_minpos, quadlow=Ntimes, quadhigh=Ntimes)\n",
    "minuit_bllh.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "minval, minpos, quadlow, quadhigh = minuit_bllh.args\n",
    "x_fit = np.linspace(bllh_minpos-min_fit, bllh_minpos+max_fit, 1000)\n",
    "y_fit_simple = func_asympara_vec(x_fit, minval,minpos,quadlow,quadhigh)\n",
    "ax_bllh.plot(x_fit, y_fit_simple, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show fit statistics in figure\n",
    "# We cannot use the LLH value to get the chi2 probability, so we must calculate\n",
    "# the chi2 given the tau found from the binned likelihood fit\n",
    "def chisquare(tau_fitted):\n",
    "    chi2 = 0.0\n",
    "    for ibin in range (Nbins) :\n",
    "        if (yExp[ibin] > 0) :\n",
    "            xlow_bin = xExp_edges[ibin]\n",
    "            xhigh_bin = xExp_edges[ibin+1]\n",
    "            nexp = Ntimes * (np.exp(-xlow_bin/tau_fitted) - np.exp(-xhigh_bin/tau_fitted))\n",
    "            chi2 += (yExp[ibin]-nexp)**2 / yExp[ibin]\n",
    "    return chi2\n",
    "fval_fit = chisquare(minpos)\n",
    "ndof_fit = chi2_object_bllh.ndof # or sum(indexes)-4\n",
    "prob_fit = stats.chi2.sf(fval_fit, ndof_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Chi2/ndf', 'Prob', 'minval', 'minpos', 'quadlow', 'quadhigh']\n",
    "values = [\"{:.3f} / {:d}\".format(fval_fit, ndof_fit), \n",
    "          \"{:.3f}\".format(prob_fit), \n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_bllh.values['minval'], minuit_bllh.errors['minval']),\n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_bllh.values['minpos'], minuit_bllh.errors['minpos']),\n",
    "          \"{:.2f} +/- {:.2f}\".format(minuit_bllh.values['quadlow'], minuit_bllh.errors['quadlow']),\n",
    "          \"{:.2f} +/- {:.2f}\".format(minuit_bllh.values['quadhigh'], minuit_bllh.errors['quadhigh']),\n",
    "          ]\n",
    "ax_bllh.text(0.55, 0.95, nice_string_output(names, values), family='monospace', transform=ax_chi2.transAxes, fontsize=10, verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range in the y-axis to draw in:\n",
    "ax_bllh.set_ylim(bllh_minval-2.0, bllh_minval+15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SavePlots: \n",
    "    fig_bllh.savefig(\"FitMinimum_bllh.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbinned Likelihood:\n",
    "# --------------------\n",
    "# Prepare figure\n",
    "fig_ullh, ax_ullh = plt.subplots(figsize=(8, 6))\n",
    "ax_ullh.set_title(\"Unbinned Likelihood\")\n",
    "ax_ullh.set_xlabel(r\"Value of $\\tau$\")\n",
    "ax_ullh.set_ylabel(\"Value of Unbinned Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot unbinned log likelihood values\n",
    "ax_ullh.plot(tau, ullh, 'k.', )\n",
    "ax_ullh.set_xlim(chi2_minpos-min_fit, chi2_minpos+2*max_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit unbinned log likelihood values with our function\n",
    "indexes = (tau>ullh_minpos-min_fit) & (tau<ullh_minpos+max_fit)\n",
    "chi2_object_ullh = Chi2Regression(func_asympara, tau[indexes], ullh[indexes])\n",
    "minuit_ullh = Minuit(chi2_object_ullh, pedantic=False, minval=ullh_minval, minpos=ullh_minpos, quadlow=Ntimes, quadhigh=Ntimes)\n",
    "minuit_ullh.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "minval, minpos, quadlow, quadhigh = minuit_ullh.args\n",
    "x_fit = np.linspace(ullh_minpos-min_fit, ullh_minpos+max_fit, 1000)\n",
    "y_fit_simple = func_asympara_vec(x_fit, minval,minpos,quadlow,quadhigh)\n",
    "ax_ullh.plot(x_fit, y_fit_simple, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show fit statistics in figure\n",
    "fval_fit = chisquare(minpos)\n",
    "ndof_fit = chi2_object_ullh.ndof\n",
    "prob_fit = stats.chi2.sf(fval_fit, ndof_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Chi2/ndf', 'Prob', 'minval', 'minpos', 'quadlow', 'quadhigh']\n",
    "values = [\"{:.3f} / {:d}\".format(fval_fit, ndof_fit), \n",
    "          \"{:.3f}\".format(prob_fit), \n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_ullh.values['minval'], minuit_ullh.errors['minval']),\n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_ullh.values['minpos'], minuit_ullh.errors['minpos']),\n",
    "          \"{:.2f} +/- {:.2f}\".format(minuit_ullh.values['quadlow'], minuit_ullh.errors['quadlow']),\n",
    "          \"{:.2f} +/- {:.2f}\".format(minuit_ullh.values['quadhigh'], minuit_ullh.errors['quadhigh']),\n",
    "          ]\n",
    "ax_ullh.text(0.55, 0.95, nice_string_output(names, values), family='monospace', transform=ax_chi2.transAxes, fontsize=10, verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range in the y-axis to draw in:\n",
    "ax_ullh.set_ylim(ullh_minval-2.0, ullh_minval+15.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SavePlots: \n",
    "    fig_ullh.savefig(\"FitMinimum_ullh.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data using iminuit (both chi2 and binned likelihood fits).\n",
    "# ---------------------------------------------------------------\n",
    "def func_exp(x, N0, tau) :\n",
    "    return N0 * 0.20/tau * np.exp(-x/tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure\n",
    "fig_fit, ax_fit = plt.subplots(figsize=(8, 6))\n",
    "ax_fit.set_title(\"tau values directly fitted with iminuit\")\n",
    "ax_fit.set_xlabel(\"Lifetimes [s]\")\n",
    "ax_fit.set_ylabel(\"Frequency [ev/0.1s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our tau values\n",
    "indexes = yExp>0 # only bins with values!\n",
    "xExp = (xExp_edges[1:] + xExp_edges[:-1])/2 # move from bins edges to bin centers\n",
    "syExp = np.sqrt(yExp) # uncertainties\n",
    "ax_fit.errorbar(xExp[indexes], yExp[indexes], syExp[indexes], fmt='k_', ecolor='k', elinewidth=1, capsize=2, capthick=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chisquare-fit tau values with our function\n",
    "chi2_object_fit = Chi2Regression(func_exp, xExp[indexes], yExp[indexes], syExp[indexes])\n",
    "# NOTE: The constant for normalization is NOT left free in order to have only ONE parameter!\n",
    "minuit_fit_chi2 = Minuit(chi2_object_fit, pedantic=False, limit_tau=(min_tau,max_tau), tau=tau_truth, fix_N0=True, N0=Ntimes)\n",
    "minuit_fit_chi2.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "N0, tau_fit_chi2 = minuit_fit_chi2.args\n",
    "x_fit = np.linspace(0, 10, 1000)\n",
    "y_fit_simple = func_exp(x_fit, N0, tau_fit_chi2)\n",
    "ax_fit.plot(x_fit, y_fit_simple, 'b-', label=\"ChiSquare fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binned likelihood-fit tau values with our function\n",
    "# extended=True because we have our own normalization in our fit function\n",
    "bllh_object_fit = BinnedLH(func_exp, t, bins=Nbins, bound=(0, tmax), extended=True)\n",
    "minuit_fit_bllh = Minuit(bllh_object_fit, pedantic=False, limit_tau=(min_tau,max_tau), tau=tau_truth, fix_N0=True, N0=Ntimes)\n",
    "minuit_fit_bllh.migrad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fit\n",
    "N0, tau_fit_bllh = minuit_fit_bllh.args\n",
    "x_fit = np.linspace(0, 10, 1000)\n",
    "y_fit_simple = func_exp(x_fit, N0, tau_fit_bllh)\n",
    "ax_fit.plot(x_fit, y_fit_simple, 'r-', label=\"Binned Likelihood fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Show fit statistics in figure\n",
    "fval_fit_chi2 = minuit_fit_chi2.fval\n",
    "# chi2_object_fit.ndof does not take into account that N0 is fixed.\n",
    "# It incorrectly gives us one degree less.\n",
    "ndof_fit_chi2 = sum(indexes)-1\n",
    "prob_fit_chi2 = stats.chi2.sf(fval_fit_chi2, ndof_fit_chi2)\n",
    "fval_fit_bllh = chisquare(tau_fit_bllh)\n",
    "# We can not use bllh_object_fit.ndof either because it uses all bins in the \n",
    "# BLLH fit, while chi2 still cannot use empty bins.\n",
    "ndof_fit_bllh = sum(indexes)-1\n",
    "prob_fit_bllh = stats.chi2.sf(fval_fit_bllh, ndof_fit_bllh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "string = \"Chi2 fit: \\n\"\n",
    "names = ['Chi2/ndf', 'Prob', 'tau']\n",
    "values = [\"{:.4f} / {:d}\".format(fval_fit_chi2, ndof_fit_chi2),\n",
    "          \"{:.3f}\".format(prob_fit_chi2),\n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_fit_chi2.values['tau'], minuit_fit_chi2.errors['tau']) ]\n",
    "string += nice_string_output(names, values)\n",
    "string += \"\\n\\nBLLH fit: \\n\"\n",
    "names = ['Chi2/ndf', 'Prob', 'tau']\n",
    "values = [\"{:.4f} / {:d}\".format(fval_fit_bllh, ndof_fit_bllh),\n",
    "          \"{:.3f}\".format(prob_fit_bllh),\n",
    "          \"{:.3f} +/- {:.3f}\".format(minuit_fit_bllh.values['tau'], minuit_fit_bllh.errors['tau']) ]\n",
    "string += nice_string_output(names, values)\n",
    "ax_fit.text(0.55, 0.95, string, family='monospace', transform=ax_fit.transAxes, fontsize=10, verticalalignment='top')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ranges:\n",
    "ax_fit.set_xlim(0, 10)\n",
    "ax_fit.set_ylim(bottom=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SavePlots) : fig_fit.savefig(\"ExponentialDist_Fitted.pdf\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, ensure that the program does not termine (and the plot disappears), before you press enter:\n",
    "try:\n",
    "    __IPYTHON__\n",
    "except:\n",
    "    raw_input('Press Enter to exit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------- #\n",
    "\n",
    "Make sure that you understand how the likelihood is different from the ChiSquare,\n",
    "and how the binned likelihood is different from the unbinned. If you don't do it,\n",
    "this exercise, and much of the course and statistics in general will be a bit lost\n",
    "on you! :-)\n",
    "\n",
    "The binned likelihood resembels the ChiSquare a bit, only the evaluation in each bin\n",
    "is different, especially if the number of events in the bin is low, as the PDF\n",
    "considered (Poisson for the LLH, Gaussian for the ChiSquare) is then different.\n",
    "\n",
    "The unbinned likelihood uses each single event, and is thus different at its core.\n",
    "This can make a different, if there are only few events and/or if each event has\n",
    "several attributes, which can't be summarized in a simple histogram with bins.\n",
    "\n",
    "\n",
    "Questions:\n",
    "----------\n",
    "1) Consider the four plots produced by running the program, starting with the one\n",
    "   showing the data and two fits (Chi2 and BLLH) to it. Do the two methods give\n",
    "   similar results, or are they different? Consider both central value and\n",
    "   uncertainty.\n",
    "   Now consider the three curves showing the chi2, bllh, and ullh as a function\n",
    "   of lifetime. Do you see the relation between the curves and the fit result?\n",
    "   Again, consider both the central values and the uncertainty.\n",
    "\n",
    "2) Try to decrease the number of exponential numbers you consider to say 10,\n",
    "   and see how things change. Does the difference between Chi2, BLLH, and ULLH\n",
    "   get bigger or not?\n",
    "\n",
    "3) Try to increase the number of exponential numbers you consider to say 5000,\n",
    "   and see what happens to the difference between Chi2 and BLLH?\n",
    "   Also, does the errors become more symetric? Perhaps you will need to consider\n",
    "   a shorter range of the fit around the mimimal value, and have to also\n",
    "   increase the number of points you calculate the chi2/bllh/ullh (or decrease\n",
    "   the range you search!), and possibly change the ranges of your plotting.\n",
    "\n",
    "Advanced Questions:\n",
    "\n",
    "4) Make (perhaps in a new program) a loop over the production of random data,\n",
    "   and try to see, if you can print (or plot) the Chi2 and BLLH results for each\n",
    "   turn. Can you spot any general trends? I.e. is the Chi2 uncertainty always\n",
    "   lower or higher than the (B/U)LLH? And are any of the estimators biased?\n",
    "\n",
    "5) Make a copy of the program and put in a different PDF (i.e. not the exponential).\n",
    "   Run it, and see if the errors are still asymetric. For the function, try either\n",
    "   e.g. a Uniform or a Gaussian.\n",
    "\n",
    "---------------------------------------------------------------------------------- #"
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
